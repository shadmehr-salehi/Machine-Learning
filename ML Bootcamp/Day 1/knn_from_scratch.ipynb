{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7taWMcG7yuqz"
      },
      "source": [
        "here is a tutorial on how to implement the k-Nearest Neighbors (kNN) algorithm from scratch in Python.\n",
        "\n",
        "Overview\n",
        "The k-Nearest Neighbors (kNN) algorithm is a type of instance-based learning, which means that it doesn't try to learn a general model, but instead memorizes the entire training dataset. When making a prediction for a new data point, the kNN algorithm finds the k closest points in the training set and uses their labels to make a prediction.\n",
        "\n",
        "In this tutorial, we will implement the kNN algorithm using Python and the NumPy library.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KY7HqHSCyuiR"
      },
      "source": [
        "## Steps:\n",
        "1. Load the dataset\n",
        "2. Split the dataset into training and testing sets\n",
        "3. Define a function to calculate the Euclidean distance between two data points\n",
        "4. Define a function to find the k nearest neighbors for a given test data point\n",
        "5. Define a function to make a prediction for a given test data point using the k nearest neighbors\n",
        "6. Evaluate the accuracy of the kNN algorithm on the testing set"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yKe0OCRO0Jnw"
      },
      "source": [
        "## Step 1: Load the dataset\n",
        "The first step is to load the dataset. In this example, we will use the Iris dataset, which is a famous dataset in machine learning that contains measurements for 150 iris flowers from three different species. We will use the scikit-learn library to load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KlwSPkAc0Nsy"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jB9uPGzA0QuO"
      },
      "source": [
        "## Step 2: Split the dataset into training and testing sets\n",
        "Next, we need to split the dataset into training and testing sets. We will use 70% of the data for training and 30% for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7KtT-KJJ0TlM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train , x_test , y_train , y_test = train_test_split(iris.data , iris.target , test_size=0.3 , shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WNYhby5U0U9W"
      },
      "source": [
        "## Step 3: Define a function to calculate the Euclidean distance between two data points\n",
        "The Euclidean distance between two points is the length of the shortest path between them in a straight line. We will use the Euclidean distance to calculate the distance between two data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6bnNwwIm0X7A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def euclidean_distance(x1, x2):\n",
        "    distance = np.linalg.norm(x1-x2)\n",
        "    return distance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j4zeZ_ae0Zpc"
      },
      "source": [
        "## Step 4: Define a function to find the k nearest neighbors for a given test data point\n",
        "The next step is to find the k nearest neighbors for a given test data point. We will do this by calculating the distance between the test data point and all the training data points, and then selecting the k data points with the shortest distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T0PfArSH0eUp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 1, 1]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_neighbors(X_train, y_train, x_test, k):\n",
        "    lst = [euclidean_distance(x,x_test) for x in X_train]\n",
        "    nearest_indices = np.argsort(lst)[:k]\n",
        "    nearest_labels = [y_train[i] for i in nearest_indices]\n",
        "    \n",
        "    return nearest_labels\n",
        "\n",
        "\n",
        "get_neighbors(x_train,y_train , [1,2,3,4] , 3 )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jnRIhQWB0e6n"
      },
      "source": [
        "## Step 5: Define a function to make a prediction for a given test data point using the k nearest neighbors\n",
        "The next step is to make a prediction for a given test data point using the k nearest neighbors. We will do this by finding the k nearest neighbors using the function we defined in step 4, and then selecting the most common class label among the neighbors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9imH7iGH0hOl"
      },
      "outputs": [],
      "source": [
        "def predict(X_train, y_train, x_test, k):\n",
        "    l = get_neighbors(X_train , y_train , x_test , k)\n",
        "    count = np.bincount(l)\n",
        "    ans = np.argmax(count)\n",
        "    return ans \n",
        "    \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n25uA7VK0l0e"
      },
      "source": [
        "## Step 6: Evaluate the accuracy of the kNN algorithm on the testing set\n",
        "\n",
        "Finally, we will evaluate the accuracy of the kNN algorithm on the testing set. We will use the predict function we defined in step 5 to make predictions for each test data point, and then compare the predicted labels with the true labels to calculate the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nVgg2fro0kx9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def accuracy(X_train, y_train, X_test, y_test, k):\n",
        "    cnt = 0 \n",
        "    for i in range(len(X_test)):\n",
        "        if predict(X_train , y_train , x_test[i] ,k) == y_test[i] :\n",
        "            cnt += 1 \n",
        "    return cnt/len(X_test)\n",
        "\n",
        "\n",
        "accuracy(x_train , y_train , x_test , y_test , 3)\n",
        "\n",
        "# print accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
