{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K7CxNd1XuS2Z"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/HooshBaaz/2022_DataAnalytics_SummerSchool/main/assets/logo3.png\" width=\"200\" height=\"200\" >\n",
        "\n",
        "<div style=\"display:block\"><br><br>\n",
        "    <div style=\"display:block\" align=left display=block> \n",
        "        <font size=5><b>Day3 - HandsOn2: Muli Label Classification & Imbalance Data</b></font><br>\n",
        "        <hr/>\n",
        "\n",
        "</div>\n",
        "\n",
        "<pre>\n",
        ".\n",
        "‚îÄ‚îÄ Dataset\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ One vs One Classification\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ One vs Rest Classification\n",
        "‚îú\n",
        "‚îú‚îÄ‚îÄ ROC/AUC\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ Different Models Performance\n",
        "‚îÇ \n",
        "‚îú‚îÄ‚îÄ Dealing with Imbalance Data\n",
        "‚îÇ\n",
        "‚îî‚îÄ‚îÄ Effect of Over-Sampling and Under Sampling\n",
        "</pre>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5laga0mAuS2b"
      },
      "source": [
        "The sections marked with a Thinking Emoji (üí≠) are those which you need to read and answer. All right, without further ado, let's get started!\n",
        "______________________________________"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b4WQdwDiuS2c"
      },
      "source": [
        "## Import Modules/Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w_Si9KWduS2c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9ozixJsHuS2d"
      },
      "source": [
        "_______________________"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "65X145eluS2e"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8lVKrbqduS2e"
      },
      "source": [
        "Before doing anything, we need to get familiar with Dataset. In this HandsON, we will focus on the standard imbalanced multi-class classification problem referred to as ‚ÄúGlass Identification‚Äù or simply `glass`. The dataset describes the chemical properties of glass and involves classifying samples of glass using their chemical properties as one of six classes. The dataset was credited to Vina Spiehler in 1987. Ignoring the sample identification number, there are nine input variables that summarize the properties of the glass dataset; they are:\n",
        "\n",
        "- RI: Refractive Index\n",
        "- Na: Sodium\n",
        "- Mg: Magnesium\n",
        "- Al: Aluminum\n",
        "- Si: Silicon\n",
        "- K: Potassium\n",
        "- Ca: Calcium\n",
        "- Ba: Barium\n",
        "- Fe: Iron\n",
        "\n",
        "The chemical compositions are measured as the weight percent in corresponding oxide."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qF3FZ3ZPuS2e"
      },
      "source": [
        "### üìñ Read Dataset and Exploration\n",
        "In this section we are going to read the dataset and have some visualizations to explore the dataset.\n",
        "\n",
        "#### üí≠ Questions\n",
        "- Read the dataset `glass.csv` considering column names which are explaiend before and use the name `Label` for the target column.\n",
        "- plot count of each label by choosing a proper plot. can you explain what is the problem in this dataset?\n",
        "\n",
        "\n",
        "**Write the answer below:** \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h4JrE9WvuS2f"
      },
      "outputs": [],
      "source": [
        "# Read csv data\n",
        "df = pd.read_csv('glass.csv')\n",
        "df = df.rename(columns={'1' :'Label'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RZov88uJuS2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot count of each label\n",
        "df['Label'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mNBEScT7uS2g"
      },
      "source": [
        "__________________________"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjr2APywuS2g"
      },
      "source": [
        "## One vs One Classification"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5K3gfpH7uS2g"
      },
      "source": [
        "Unlike the dataset that you work on in the morning session, this dataset is Multiclass. Thus we can not use models like `svm` and `logistic regression` directly to classify multiclass data, because they are designed for binary classification. We need to use techniques to concur this problem. classifying One-vs-One is a heuristic method for using binary classification algorithms for multi-class classification. In this section we are going to deal with this problem.\n",
        "\n",
        "\n",
        "#### üí≠ Questions\n",
        "- As always, Split data into two parts: Train and Test. use 20% of data for test.\n",
        "- Define a logistic regression model.\n",
        "- Use the `One-vs-One` method of the sklearn library to define a classifier for multiclass data.\n",
        "- Train your model on Train data and get predictions for test data.\n",
        "- As the data is imbalanced, select a proper evaluation metric and evaluate your model.\n",
        "\n",
        "\n",
        "**Write the answer below:** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u61hxC_huS2g"
      },
      "outputs": [],
      "source": [
        "# Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop('Label' , axis=1)\n",
        "y = df['Label']\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y , test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(170, 9)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-GIPQA7FuS2h"
      },
      "outputs": [],
      "source": [
        "#define logitic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "estimator = LogisticRegression(max_iter=10000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vb-rGCQcuS2h"
      },
      "outputs": [],
      "source": [
        "# define one vs one classfier and train and predict labels for test data\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "ovo = OneVsOneClassifier(estimator).fit(X_train , y_train)\n",
        "y_pred = ovo.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g-r1heZ2uS2h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.57      0.67      0.62        12\n",
            "           2       0.46      0.40      0.43        15\n",
            "           3       0.00      0.00      0.00         0\n",
            "           5       0.33      0.33      0.33         3\n",
            "           6       0.33      0.33      0.33         3\n",
            "           7       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.56        43\n",
            "   macro avg       0.43      0.42      0.43        43\n",
            "weighted avg       0.57      0.56      0.56        43\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shadm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\shadm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\shadm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# evaluate your classifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_pred , y_test))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "89SPPHKtuS2h"
      },
      "source": [
        "__________________________"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xf_wfyNPuS2h"
      },
      "source": [
        "## One vs Rest Classification"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gb6zKBnFuS2h"
      },
      "source": [
        "One-vs-rest (OvR for short, also referred to as One-vs-All or OvA) is another heuristic method for using binary classification algorithms for multi-class classification. It involves splitting the multi-class dataset into multiple binary classification problems. A binary classifier is then trained on each binary classification problem and predictions are made using the model that is the most confident. In this section we will use this technique to classify our multiclass data.\n",
        "#### üí≠ Questions\n",
        "- Define a new linear model (in this section `logistic regression`)\n",
        "- Use the `One-vs-Rest` method of the sklearn library to define a classifier for multiclass data.\n",
        "- Train your model on Train data that you have splitted in the last section and get predictions for test data.\n",
        "- Evaluate your model with the same metric that you have evaluated your `one-vs-one` model.\n",
        "\n",
        "\n",
        "**Write the answer below:** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_qVJNwyRuS2i"
      },
      "outputs": [],
      "source": [
        "#define logitic regression model\n",
        "estimator2 = LogisticRegression(max_iter=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "s3oAUbjSuS2i"
      },
      "outputs": [],
      "source": [
        "# define one vs all classfier and train and predict labels for test data\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "ovr = OneVsRestClassifier(estimator2).fit(X_train , y_train)\n",
        "y_pred2 = ovr.predict(X_test)\n",
        "probs = ovr.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 2, 7, 7, 7, 1, 6, 1, 2, 2, 2, 2, 2, 1, 7, 1, 5, 1, 6, 1, 1,\n",
              "       1, 7, 7, 5, 7, 2, 1, 1, 1, 2, 5, 6, 7, 2, 7, 2, 2, 7, 7, 2, 1],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TB0xGbwluS2i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.71      0.71      0.71        14\n",
            "           2       0.50      0.46      0.48        13\n",
            "           3       0.00      0.00      0.00         1\n",
            "           5       0.33      0.33      0.33         3\n",
            "           6       0.33      0.33      0.33         3\n",
            "           7       0.82      1.00      0.90         9\n",
            "\n",
            "    accuracy                           0.63        43\n",
            "   macro avg       0.45      0.47      0.46        43\n",
            "weighted avg       0.60      0.63      0.61        43\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shadm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\shadm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\shadm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# evaluate your classifier\n",
        "print(classification_report(y_test, y_pred2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eX8gEqogxdIH"
      },
      "source": [
        "### üìñ ROC/AUC\n",
        "The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers. In this section we are going to plot ROC and compute AUC for our classifier.\n",
        "\n",
        "\n",
        "#### üí≠ Questions\n",
        "- plot `ROC` curve for the classifier.\n",
        "- Calculate `AUC` for the one vs one classfier you trained on data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Write the answer below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "12XnrZt4xdII"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x21b51173970>]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Roc\n",
        "from sklearn.metrics import  roc_curve, auc \n",
        "\n",
        "fpr , tpr , thold = roc_curve(y_test,probs , pos_label=1)\n",
        "\n",
        "\n",
        "plt.plot(fpr , tpr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_kiGzXhRxdII"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7266009852216749\n"
          ]
        }
      ],
      "source": [
        "# Auc\n",
        "# from sklearn.metrics import RocCurveDisplay.from_estimator\n",
        "roc_auc = auc(fpr , tpr)\n",
        "print(roc_auc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oqtC823wuS2i"
      },
      "source": [
        "__________________________"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V40tu854uS2i"
      },
      "source": [
        "## Different Models Performance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWrxUygmuS2i"
      },
      "source": [
        "In this section we are going to compare performance of different classifiers on our data.\n",
        "#### üí≠ Questions\n",
        "- Define Models like `KNN`, `Gaussian Naive Bayes` which are inherently for multiclass classification and `logistic regression` by choosing the parameter `multi_class=multinomial`\n",
        "- Use train data that you have splitted in the second section to train your models.\n",
        "- predict labels for test data.\n",
        "- evaluate your models using the metric that you have chosen for the last two sections.\n",
        "- which model has the best performance?\n",
        "\n",
        "\n",
        "**Write the answer below:** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TM9vtV-fuS2j"
      },
      "outputs": [],
      "source": [
        "# define models\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "knn = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uddiFmfEuS2j"
      },
      "outputs": [],
      "source": [
        "# Train Models\n",
        "knn.fit(X_train,y_train)\n",
        "lr.fit(X_train,y_train)\n",
        "nb.fit(X_train,y_train)\n",
        "\n",
        "lr_pred = lr.predict(X_test)\n",
        "nb_pred = nb.predict(X_test)\n",
        "knn_pred = knn.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9E4fU9oQuS2j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "knn score = 0.7209302325581395 \n",
            " lr score = 0.6511627906976745 \n",
            " nb score = 0.6511627906976745\n"
          ]
        }
      ],
      "source": [
        "# Evaluate models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(f\"knn score = {accuracy_score(y_test , knn_pred)} \\n lr score = {accuracy_score(y_test , lr_pred)} \\n nb score = {accuracy_score(y_test , nb_pred)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TLLjvMwJuS2j"
      },
      "source": [
        "______________________________"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kJWOXdJEuS2j"
      },
      "source": [
        "## Dealing with Imbalance Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9ejjXaUJuS2j"
      },
      "source": [
        "As you may have noticed up to now, the dataset that we have in this handsOn and the dataset that we had in the morning session are both imbalanced. Imbalanced datasets may often produce poor performance when running a Machine Learning model, although, in some cases the evaluation metrics produce good results. This can be due to the fact that the model is good at predicting the majority class, but it has poor performance while predicting the minority class. Since the evaluation metrics calculate the average value between the majority and minority classes, the final performance looks ok.\n",
        "\n",
        "In this part of HandsOn we are going to introduce different techniques to deal with Imbalanced data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VWpbS96iuS2j"
      },
      "source": [
        "### Random Undersampling\n",
        "As the name suggests, random undersampling reduces the number of majority classes randomly down to the desired ratio against the minority class. This is probably the easiest way to undersample and can actually yield good results if there are a lot of the majority class instances that are close to each other.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### üí≠ Questions\n",
        "- First you need to install an `imbalanced-learn` library to work with this section's methods.\n",
        "- Use the method for `Random Under Sampling` from the library you have installed to under-sample the train data that you have Splitted in the second section.\n",
        "- print the shape of train data after undersampling.\n",
        "- Train models on the new resampled train data and evaluate your models on the test data from section two.\n",
        "- Compare the performance with the models that you have trained on the imbalanced data. Is there any improvement?\n",
        "\n",
        "\n",
        "\n",
        "**Write the answer below:** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "H47kHspOuS2k"
      },
      "outputs": [],
      "source": [
        "# pip install imblearn\n",
        "#! pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(170, 9)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LY5F-0H5uS2k"
      },
      "outputs": [],
      "source": [
        "# Under sample\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler()\n",
        "X_resample , y_resample = rus.fit_resample(X_train , y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jN3kXvYIuS2k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(36, 9)\n",
            "(36,)\n"
          ]
        }
      ],
      "source": [
        "# Print shape of data\n",
        "print(X_resample.shape)\n",
        "print(y_resample.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4NJuDdNIuS2k"
      },
      "outputs": [],
      "source": [
        "# Train Models\n",
        "nb_2 = GaussianNB()\n",
        "lr_2 = LogisticRegression(max_iter=10000)\n",
        "knn_2 = KNeighborsClassifier()\n",
        "\n",
        "knn_2.fit(X_resample,y_resample)\n",
        "lr_2.fit(X_resample,y_resample)\n",
        "nb_2.fit(X_resample,y_resample)\n",
        "\n",
        "lr_pred_2 = lr_2.predict(X_test)\n",
        "nb_pred_2 = nb_2.predict(X_test)\n",
        "knn_pred_2 = knn_2.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5lRT6DWluS2k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "knn score = 0.4418604651162791 \n",
            " lr score = 0.37209302325581395 \n",
            " nb score = 0.6046511627906976\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Models\n",
        "print(f\"knn score = {accuracy_score(y_test , knn_pred_2)} \\n lr score = {accuracy_score(y_test , lr_pred_2)} \\n nb score = {accuracy_score(y_test , nb_pred_2)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0JAmq7SeuS2k"
      },
      "source": [
        "### Oversampling with SMOTE\n",
        "For over-sampling techniques, SMOTE (Synthetic Minority Oversampling Technique) is considered as one of the most popular and influential data sampling algorithms in ML and data mining. With SMOTE, the minority class is over-sampled by creating ‚Äúsynthetic‚Äù examples rather than by over-sampling with replacement.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### üí≠ Questions\n",
        "- Use the method for `SMOTE` from the library you have installed to under-sample the train data that you have Splitted in the second section.\n",
        "- print the shape of train data after oversampling.\n",
        "- Train models on the new resampled train data and evaluate your models on the test data from section two.\n",
        "- Compare the performance with the models that you have trained on the imbalanced data and when you have undersampled. Is there any improvement?\n",
        "\n",
        "\n",
        "**Write the answer below:** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gDhOWQz7uS2p"
      },
      "outputs": [],
      "source": [
        "#! pip install -U threadpoolctl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gzsSgsaBuS2p"
      },
      "outputs": [],
      "source": [
        "# Oversampling \n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "\n",
        "X_resample_2 , y_resample_2 = smote.fit_resample(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Oc8qi0M5uS2q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(378, 9)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print shape of data\n",
        "X_resample_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1c9-P98nuS2q"
      },
      "outputs": [],
      "source": [
        "# Train Models\n",
        "nb_3 = GaussianNB()\n",
        "lr_3 = LogisticRegression(max_iter=10000)\n",
        "knn_3 = KNeighborsClassifier()\n",
        "\n",
        "knn_3.fit(X_resample_2,y_resample_2)\n",
        "lr_3.fit(X_resample_2,y_resample_2)\n",
        "nb_3.fit(X_resample_2,y_resample_2)\n",
        "\n",
        "lr_pred_3 = lr_3.predict(X_test)\n",
        "nb_pred_3 = nb_3.predict(X_test)\n",
        "knn_pred_3 = knn_3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KsFs77F_uS2q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "knn score = 0.6511627906976745 \n",
            " lr score = 0.627906976744186 \n",
            " nb score = 0.5348837209302325\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Models\n",
        "print(f\"knn score = {accuracy_score(y_test , knn_pred_3)} \\n lr score = {accuracy_score(y_test , lr_pred_3)} \\n nb score = {accuracy_score(y_test , nb_pred_3)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6a11fdCmuS2q"
      },
      "source": [
        "___________________________"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R7UMtxC2uS2q"
      },
      "source": [
        "## Effect of Over-Sampling and Under Sampling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qyOLWqbiuS2q"
      },
      "source": [
        "In this section we want to compare the effect of methods that we have used to deal with imbalanced datasets.\n",
        "#### üí≠ Questions\n",
        "- plot a bar plot to compare the effect of methods we have used for balancing datasets. The x-axis of this plot must be classifiers in 3 conditions (imbalanced data, undersampling and oversampling) and the y-axis must be the metric that you have chosen to compare classifiers.\n",
        "\n",
        "\n",
        "**Write the answer below:** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IDo2O6WQuS2q"
      },
      "outputs": [],
      "source": [
        "# Compare\n",
        "names = ['Knn' , 'NB' , 'LR']\n",
        "types = ['imbalanced ' , ', undersampling' , 'oversampling']\n",
        "knns = [accuracy_score(knn_pred , y_test) , accuracy_score(knn_pred_2 , y_test)  , accuracy_score(knn_pred_3 , y_test) ]\n",
        "nbs = [accuracy_score(nb_pred , y_test) , accuracy_score(nb_pred_2 , y_test) ,accuracy_score(nb_pred_3 , y_test)]\n",
        "lrs = [accuracy_score(lr_pred , y_test), accuracy_score(lr_pred_2 , y_test) , accuracy_score(lr_pred_3 , y_test)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x21b536fc460>,\n",
              "  <matplotlib.axis.XTick at 0x21b536fc430>,\n",
              "  <matplotlib.axis.XTick at 0x21b536f60d0>],\n",
              " [Text(0.25, 0, 'imbalance'),\n",
              "  Text(1.25, 0, 'undersample'),\n",
              "  Text(2.25, 0, 'oversample')])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXg0lEQVR4nO3df5xV9X3n8dd7+BlEScQxqww6aMe6NFqsE5KqtWTXpLjpAn2UGNDW8NBK3EiJkHSDjyY8qO0jm5+la2T7CIaoXU0IUZtgZEOoDVJNVEYk4oDYWaRhqA8dKSEFdwTiZ/84Z/A63OGembnz68v7+XjMY86P773nc8+5933P/d5zzlVEYGZmQ1/NQBdgZmbV4UA3M0uEA93MLBEOdDOzRDjQzcwSMXygFnzGGWdEfX39QC3ezGxIeuaZZ16LiNpy8wYs0Ovr62lqahqoxZuZDUmS/qWree5yMTNLhAPdzCwRDnQzs0QMWB+6mVk1HDlyhNbWVtrb2we6lKoaPXo0dXV1jBgxovBtHOhmNqS1trZy6qmnUl9fj6SBLqcqIoJ9+/bR2trKpEmTCt/OXS5mNqS1t7czfvz4ZMIcQBLjx4/v9qcOB7qZDXkphXmHnjwmB7qZWSLch25mSalf8khV72/3Fz5csc3YsWM5ePAgAOvWrePWW29lw4YNnHvuuVWtpZIhGejV3mCVFNmgZmaPPvooCxcuZP369f0e5uAuFzOzqti0aRM33XQTP/jBDzj//PMBmDdvHgsXLuSyyy7jvPPO44EHHgBg48aNTJs2jdmzZ3PhhRdy3XXXUY1fjxuSe+hmZoPJG2+8waxZs9i4cSMXXnjh2+a9/PLLPP7447zwwgvMmDGD2bNnA/Dss8/S3NzM2WefzeWXX84TTzzBFVdc0as6Cu2hS5ouaaekFklLysxfLmlr/veipF/0qiozsyFkxIgRXHbZZaxateq4ebNmzaKmpobJkyfzyiuvHJs+depU6urqqKmpYcqUKezevbvXdVQMdEnDgBXA1cBkYK6kyaVtImJRREyJiCnA14CHel2ZmdkQUVNTw5o1a3j66af5/Oc//7Z5o0aNOjZc2q1SOn3YsGEcPXq093UUaDMVaImIXRFxGFgNzDxB+7nAt3tdmZnZEDJmzBgeeeQR7r///rJ76v2hSB/6BGBPyXgr8L5yDSWdC0wC/rGL+fOB+QDnnHNOtwo1MytiII9KO/300/nhD3/IlVdeSW1t2d+g6FPV/lJ0DvBARPyq3MyIWAmsBGhsbOz9V7pmZoNAxzHoABMnTuSll14CYMaMGWXbTZs2jWnTph2bfuedd1aljiJdLnuBiSXjdfm0cubg7hYzswFRJNA3Aw2SJkkaSRbaazs3knQh8C7gp9Ut0czMiqgY6BFxFFgArAd2AGsiolnS7ZJKP0/MAVZHNY6ONzOzbivUhx4R64B1naYt7TS+rHplmZlZd/nUfzOzRDjQzcwS4Wu5mFlalo2r8v0dqNhEEosXL+arX/0qAF/5ylc4ePAgy5YtY9myZdx1113U1tbS3t7OBz7wAVasWEFNTfX3p72HbmbWS6NGjeKhhx7itddeKzt/0aJFbN26le3bt7Nt2zYee+yxPqnDgW5m1kvDhw9n/vz5LF++/ITtDh8+THt7O+9617v6pA4HuplZFdxyyy3cf//9HDhwfBfN8uXLmTJlCmeddRYXXHABU6ZM6ZMaHOhmZlVw2mmncf3113PHHXccN6+jy+XVV1/l0KFDrF69uk9qcKCbmVXJrbfeyqpVqzh06FDZ+SNGjGD69Ols2rSpT5bvo1yKqPa35hVcNKn/rkS57WPb+m1ZNrT152/5DtXf8T399NO55pprWLVqFTfccMNx8yOCJ554gksuuaRPlu9AN7O0FDjMsC996lOfOu7qicuXL+e+++7jyJEjXHzxxXziE5/ok2U70M3Meqn08rnvfve7ef3114+NdxyL3h/ch25mlggHuplZIhzoZmaJcB+6mQ0+3Tmy7PfWwL+29255Z/fNUSf9zXvoZmaJcKCbmSXCXS5mlpSLNlxf1fsrcvLd2LFj33boIvC2y+YePnyYz33uc8ydO7eqtXXmPXQzsz7ScQ2X73//+3z84x/nyJEjfbq8QoEuabqknZJaJC3pos01krZLapb0reqWaWY2dDU0NDBmzBj279/fp8up2OUiaRiwAvgg0ApslrQ2IraXtGkAbgMuj4j9ks7sq4LNzIaaLVu20NDQwJln9m00FulDnwq0RMQuAEmrgZnA9pI2NwErImI/QES8Wu1CzQa7i+69qF+X5wurDX7Lly/n7rvv5sUXX+Thhx/u8+UV6XKZAOwpGW/Np5W6ALhA0hOSnpQ0vdwdSZovqUlSU1tbW88qNjMbIhYtWkRzczMPPvggN954I+3tvTxevoJqfSk6HGgApgFzgbskvbNzo4hYGRGNEdFYW1tbpUWbmQ1uM2bMoLGxkXvvvbdPl1Oky2UvMLFkvC6fVqoVeCoijgAvSXqRLOA3V6VKM7OCtn3w77p/o16eKfr6669TV1d3bHzx4sXHtVm6dCnXXnstN910EzU1fXOAYZFA3ww0SJpEFuRzgGs7tfke2Z753ZLOIOuC2VXFOs3MBq0333yzYptLL72UnTt39mkdFd8mIuIosABYD+wA1kREs6TbJc3Im60H9knaDvwY+LOI2NdXRZuZ2fEKnSkaEeuAdZ2mLS0ZDmBx/mdmZgPAZ4qa2RAXZPuUaenJY3Kgm9mQNvrALvYdOppUqEcE+/btY/To0d26nS/OZWZDWt2WL9LKZ2gbdx6gnt3JgR1VrakaRo8e/bYjZ4pwoJvZkDbi8C+Y9ORtvbuTZQeqU8wAc5eLmVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkifKaomZ30Uvk9WO+hm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpaIQoEuabqknZJaJC0pM3+epDZJW/O/P6l+qWZmdiIVj0OXNAxYAXwQaAU2S1obEds7Nf1ORCzogxrNzKyAInvoU4GWiNgVEYeB1cDMvi3LzMy6q0igTwD2lIy35tM6+0NJz0l6QNLEcnckab6kJklNbW1tPSjXzMy6Uq0vRR8G6iPiYmADcG+5RhGxMiIaI6Kxtra2Sos2MzMoFuh7gdI97rp82jERsS8i3shHvwFcWp3yzMysqCKBvhlokDRJ0khgDrC2tIGks0pGZwA7qleimZkVUfEol4g4KmkBsB4YBnwzIpol3Q40RcRaYKGkGcBR4N+AeX1Ys5mZlVHo8rkRsQ5Y12na0pLh24DbqluamZl1h88UNTNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0QUupaLWbXUL3mkX5e3+wsf7tflmQ0k76GbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJKBTokqZL2impRdKSE7T7Q0khqbF6JZqZWREVA13SMGAFcDUwGZgraXKZdqcCnwSeqnaRZmZWWZE99KlAS0TsiojDwGpgZpl2fwl8EWivYn1mZlZQkUCfAOwpGW/Npx0j6beAiRFxwgt1SJovqUlSU1tbW7eLNTOzrvX6S1FJNcBfA5+q1DYiVkZEY0Q01tbW9nbRZmZWokig7wUmlozX5dM6nAq8B9goaTfwfmCtvxg1M+tfRQJ9M9AgaZKkkcAcYG3HzIg4EBFnRER9RNQDTwIzIqKpTyo2M7OyKgZ6RBwFFgDrgR3AmoholnS7pBl9XaCZmRVT6AcuImIdsK7TtKVdtJ3W+7LMzKy7fKaomVkiHOhmZonwb4pa2paN679lTTqn/5ZlVob30M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0QUCnRJ0yXtlNQiaUmZ+TdL2iZpq6THJU2ufqlmZnYiFQNd0jBgBXA1MBmYWyawvxURF0XEFOBLwF9Xu1AzMzuxInvoU4GWiNgVEYeB1cDM0gYR8cuS0VOAqF6JZmZWRJHfFJ0A7CkZbwXe17mRpFuAxcBI4D9VpTozMyusal+KRsSKiDgf+Azw2XJtJM2X1CSpqa2trVqLNjMzigX6XmBiyXhdPq0rq4FZ5WZExMqIaIyIxtra2sJFmplZZUUCfTPQIGmSpJHAHGBtaQNJDSWjHwb+uXolmplZERX70CPiqKQFwHpgGPDNiGiWdDvQFBFrgQWSrgKOAPuBj/Vl0WZmdrwiX4oSEeuAdZ2mLS0Z/mSV6zIzs27ymaJmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiCgW6pOmSdkpqkbSkzPzFkrZLek7So5LOrX6pZmZ2IhUDXdIwYAVwNTAZmCtpcqdmzwKNEXEx8ADwpWoXamZmJ1ZkD30q0BIRuyLiMLAamFnaICJ+HBGv56NPAnXVLdPMzCopEugTgD0l4635tK7cCPyfcjMkzZfUJKmpra2teJVmZlZRVb8UlfRHQCPw5XLzI2JlRDRGRGNtbW01F21mdtIbXqDNXmBiyXhdPu1tJF0F/DnwuxHxRnXKMzOzoorsoW8GGiRNkjQSmAOsLW0g6RLg68CMiHi1+mWamVklFQM9Io4CC4D1wA5gTUQ0S7pd0oy82ZeBscB3JW2VtLaLuzMzsz5SpMuFiFgHrOs0bWnJ8FVVrsvMzLrJZ4qamSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJKBTokqZL2impRdKSMvOvlLRF0lFJs6tfppmZVVIx0CUNA1YAVwOTgbmSJndq9nNgHvCtahdoZmbFDC/QZirQEhG7ACStBmYC2zsaRMTufN6bfVCjmZkVUKTLZQKwp2S8NZ/WbZLmS2qS1NTW1taTuzAzsy7065eiEbEyIhojorG2trY/F21mlrwigb4XmFgyXpdPMzOzQaRIoG8GGiRNkjQSmAOs7duyzMysuyoGekQcBRYA64EdwJqIaJZ0u6QZAJLeK6kV+AjwdUnNfVm0mZkdr8hRLkTEOmBdp2lLS4Y3k3XFmJnZAPGZomZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIKBbqk6ZJ2SmqRtKTM/FGSvpPPf0pSfdUrNTOzE6oY6JKGASuAq4HJwFxJkzs1uxHYHxG/BiwHvljtQs3M7MSK7KFPBVoiYldEHAZWAzM7tZkJ3JsPPwD8Z0mqXplmZlbJ8AJtJgB7SsZbgfd11SYijko6AIwHXittJGk+MD8fPShpZ0+K7m+9eGc6g07roJjne77EbtK8tN93e/joBv12g7S3XcqvOej1tju3qxlFAr1qImIlsLI/lzmQJDVFRONA12Hd4+02dJ3s265Il8teYGLJeF0+rWwbScOBccC+ahRoZmbFFAn0zUCDpEmSRgJzgLWd2qwFPpYPzwb+MSKiemWamVklFbtc8j7xBcB6YBjwzYholnQ70BQRa4FVwP+W1AL8G1no20nUvZQYb7eh66TedvKOtJlZGnymqJlZIhzoZmaJOGkDXdJPutn+Hkmzu9G+XlL/Htxqx0jaKGnQHr4maZ6kOwe6Djux7r7uB9pJG+gRcdlA12CDR36JCxvElDlpM6uIk3blSDqY/58m6TFJ35e0S9IXJF0n6WlJ2ySdX3KzqyQ1SXpR0u/nt6+X9E+StuR/x71RdNUmX/ZGSQ9IekHS/R2XTJD0Xkk/kfSzvJZTJQ2T9GVJmyU9J+nj/bCqBkTnTziSPi1pWb6+vpivkxcl/U4+/x2SVkvaIenvgXeU3PZDkn6ar/vvShqbT9+d39cW4COSFkranq/b1Xmbqfltn823x6/n0+dJ+p6kDfn9LJC0OG/3pKTT83YbJf1PSVslPS9papnHWivpwXy7bpZ0eV+u2/6Ur5Pn879b89fXLSXzl0n6dD78ZyXP7b/Ip9UruzDg35Gdzjkx32t+Pn99Lsrb3ZTf9mf5uhyTT79H0t/m22RX/pr7Zv48uaekjoOSlktqlvSopNoyj+VSZVnxjKT1ks7q05XXExFxUv4BB/P/04BfAGcBo8hOkvqLfN4ngb/Jh+8Bfkj2JthAdgmE0cAYYHTepoHsUE6AeuD5fLirNtOAA2Qna9UAPwWuAEYCu4D35u1OIzvEdD7w2XzaKKAJmDTQ67KPts+x9ZePfxpYBmwEvppP+y/AP+TDi8kOqQW4GDgKNJKdCr4JOCWf9xlgaT68G/jvJcv4V2BUPvzO0nWfD18FPJgPzwNagFOB2nw73pzPWw7cmg9vBO7Kh68seU7MA+7Mh78FXJEPnwPsGOj1X6VteCmwDTgFGAs0A5cAj5W02U52UuKHyA45VP5a+EG+vuqBN4H3l9znhpLbd2yn8SXT/gr403z4HrLrT4nsmlO/BC7Kl/EMMCVvF8B1+fDSkm1zD9m5NSOAnwC1+fSPdjzfBtNfv576P4htjoiXAST9X+BH+fRtwAdK2q2JiDeBf5a0C7gQeAm4U9IU4FfABWXuf8QJ2jwdEa35sreSPYEPAC9HxGaAiPhlPv9DwMV6q09vHNkbxEs9feBD1EP5/2fI1hdkL/47ACLiOUnP5dPfT3aV0CfyDz8jyd44O3ynZPg54H5J3wO+l08bB9wrqYHsRT+ipP2PI+LfgX9Xdv2ih/Pp28jeVDp8O69rk6TTJL2z0+O5Cpist65nd5qksRFxsOtVMCRcAfx9RBwCkPQQ8DvAmZLOJnsj3B8ReyR9kizUn81vO5bsuf1z4F8i4sl8+i7gPElfAx7hrdfqeyT9FfDO/LbrS+p4OCJC0jbglYjYltfTTPb82Ur2ptHxXLiPt55jHX4deA+wId9Ow4CXe7Za+o4DPfNGyfCbJeNv8vZ11Pmg/QAWAa8Av0n2rt9e5v5P1KZ02b/ixNtEZHse60/QJhVHeXuX4OiS4Y51Vml9QbbONkTE3C7mHyoZ/jDZG8N/Bf5c0kXAX5IF9x8ou87/xjJ1QPefN6VqyPZAyz13UvRdsr3e/8BbISrgf0TE10sb5uv82DaKiP2SfhP4PeBm4BrgBrI96VkR8TNJ88g+/XYo3S6dt1lXz5/O20hAc0T8dsVHN4BO2j70HvqIpBpl/ernATvJ9uBezvfc/5jsnbuzIm1K7QTOkvReAGX958PJ9jr+m6QR+fQLJJ1SjQc2CL1Ctic3XtIo4PcrtN8EXAsg6T28tYf8JHC5pF/L550i6bhPUcq+bJsYET8m65YZR7anN463rl00r4eP5aP5Mq4ADkTEgU7zfwT8aUktU3q4nMHmn4BZksbkz9M/yKd9h+xs8tlk4Q7Zc/uGku83Jkg6s/MdSjoDqImIB4HPAr+VzzoVeDl/bVzXg1pr8nogex493mn+TqBW0m/ndYyQ9Bs9WE6f8h569/wceJqsX/XmiGiX9L+AByVdT9bHfqjM7Yq0OSYiDkv6KPA1Se8A/h/Zx/JvkH1E3KLsc18bMKsaD2ywiYgjyi4v8TRZoL5Q4SZ/C9wtaQewg6w7hohoy/fYvp2/MUAWBC92uv0w4D5J48j2xu6IiF9I+hJZl8tnyT7i90S7pGfJumtuKDN/IbAi7yYaTvbmdHMPlzVoRMSW/IvHp/NJ34iIZyHbSQH2dnR1RsSPJP1H4Kd5l8ZB4I/IPoWVmkC2nTt2Rm/L/38OeIrsNfEUWcB3xyFgar6dXyV/Ey55LIfzrs478ufIcOBvyL4XGDR86r9ZH5K0Efh0RDQNdC3WNUkHI2LsQNfRW+5yMTNLhPfQzcwS4T10M7NEONDNzBLhQDczS4QD3cwsEQ50M7NE/H9LWegriWOQrQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "barWidth = 0.25\n",
        "x = np.arange(3)\n",
        "plt.bar(x, knns, width=0.25,)\n",
        "plt.bar(x+0.25, lrs, width=0.25)\n",
        "plt.bar(x+0.5,nbs, width=0.25)\n",
        "plt.legend(names)\n",
        "plt.xticks([0.25, 1.25, 2.25], ['imbalance', 'undersample', 'oversample'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
